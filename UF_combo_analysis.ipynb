{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textacy import text_stats, make_spacy_doc\n",
    "from scipy.stats import pointbiserialr\n",
    "from scipy.stats import zscore, gmean\n",
    "from datasets import Dataset, load_dataset\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.DataFrame(load_dataset(\"argilla/ultrafeedback-binarized-preferences-cleaned\")[\"train\"]).sample(n=15000, random_state=42)\n",
    "df_clean = df_sample.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>prompt</th>\n",
       "      <th>chosen</th>\n",
       "      <th>chosen-rating</th>\n",
       "      <th>chosen-model</th>\n",
       "      <th>rejected</th>\n",
       "      <th>rejected-rating</th>\n",
       "      <th>rejected-model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>Topics: Wound management for general practitio...</td>\n",
       "      <td>[{'content': 'Topics: Wound management for gen...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>[{'content': 'Topics: Wound management for gen...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>ultralm-13b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flan_v2_niv2</td>\n",
       "      <td>Part 1. Definition\\nIn this task, you are give...</td>\n",
       "      <td>[{'content': 'Part 1. Definition\n",
       "In this task,...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>[{'content': 'Part 1. Definition\n",
       "In this task,...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>vicuna-33b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>You will act as an voice changer. You will cha...</td>\n",
       "      <td>[{'content': 'You will act as an voice changer...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>[{'content': 'You will act as an voice changer...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>ultralm-13b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ultrachat</td>\n",
       "      <td>Write a well-researched paper on the physiolog...</td>\n",
       "      <td>[{'content': 'Write a well-researched paper on...</td>\n",
       "      <td>4.75</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>[{'content': 'Write a well-researched paper on...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>ultralm-13b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ultrachat</td>\n",
       "      <td>Create a step-by-step recipe for making fluffy...</td>\n",
       "      <td>[{'content': 'Create a step-by-step recipe for...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>[{'content': 'Create a step-by-step recipe for...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>falcon-40b-instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>flan_v2_cot</td>\n",
       "      <td>[QUESTION] If \"Two kids stepping stones over t...</td>\n",
       "      <td>[{'content': '[QUESTION] If \"Two kids stepping...</td>\n",
       "      <td>4.75</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>[{'content': '[QUESTION] If \"Two kids stepping...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>flan_v2_niv2</td>\n",
       "      <td>Instructions: Given an object and a part, deci...</td>\n",
       "      <td>[{'content': 'Instructions: Given an object an...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>[{'content': 'Instructions: Given an object an...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>Write me a letter asking my friend Dan what he...</td>\n",
       "      <td>[{'content': 'Write me a letter asking my frie...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>ultralm-13b</td>\n",
       "      <td>[{'content': 'Write me a letter asking my frie...</td>\n",
       "      <td>1.25</td>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>flan_v2_niv2</td>\n",
       "      <td>You will be given a definition of a task first...</td>\n",
       "      <td>[{'content': 'You will be given a definition o...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>[{'content': 'You will be given a definition o...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>vicuna-33b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>false_qa</td>\n",
       "      <td>What's the resolution of a cat?</td>\n",
       "      <td>[{'content': 'What's the resolution of a cat?'...</td>\n",
       "      <td>4.25</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>[{'content': 'What's the resolution of a cat?'...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>wizardlm-70b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             source                                             prompt  \\\n",
       "0          sharegpt  Topics: Wound management for general practitio...   \n",
       "1      flan_v2_niv2  Part 1. Definition\\nIn this task, you are give...   \n",
       "2          sharegpt  You will act as an voice changer. You will cha...   \n",
       "3         ultrachat  Write a well-researched paper on the physiolog...   \n",
       "4         ultrachat  Create a step-by-step recipe for making fluffy...   \n",
       "...             ...                                                ...   \n",
       "14995   flan_v2_cot  [QUESTION] If \"Two kids stepping stones over t...   \n",
       "14996  flan_v2_niv2  Instructions: Given an object and a part, deci...   \n",
       "14997      sharegpt  Write me a letter asking my friend Dan what he...   \n",
       "14998  flan_v2_niv2  You will be given a definition of a task first...   \n",
       "14999      false_qa                    What's the resolution of a cat?   \n",
       "\n",
       "                                                  chosen  chosen-rating  \\\n",
       "0      [{'content': 'Topics: Wound management for gen...           5.00   \n",
       "1      [{'content': 'Part 1. Definition\n",
       "In this task,...           4.50   \n",
       "2      [{'content': 'You will act as an voice changer...           4.50   \n",
       "3      [{'content': 'Write a well-researched paper on...           4.75   \n",
       "4      [{'content': 'Create a step-by-step recipe for...           5.00   \n",
       "...                                                  ...            ...   \n",
       "14995  [{'content': '[QUESTION] If \"Two kids stepping...           4.75   \n",
       "14996  [{'content': 'Instructions: Given an object an...           4.50   \n",
       "14997  [{'content': 'Write me a letter asking my frie...           4.50   \n",
       "14998  [{'content': 'You will be given a definition o...           2.00   \n",
       "14999  [{'content': 'What's the resolution of a cat?'...           4.25   \n",
       "\n",
       "           chosen-model                                           rejected  \\\n",
       "0          wizardlm-70b  [{'content': 'Topics: Wound management for gen...   \n",
       "1          wizardlm-70b  [{'content': 'Part 1. Definition\n",
       "In this task,...   \n",
       "2          wizardlm-13b  [{'content': 'You will act as an voice changer...   \n",
       "3          wizardlm-13b  [{'content': 'Write a well-researched paper on...   \n",
       "4       llama-2-7b-chat  [{'content': 'Create a step-by-step recipe for...   \n",
       "...                 ...                                                ...   \n",
       "14995     gpt-3.5-turbo  [{'content': '[QUESTION] If \"Two kids stepping...   \n",
       "14996        vicuna-33b  [{'content': 'Instructions: Given an object an...   \n",
       "14997       ultralm-13b  [{'content': 'Write me a letter asking my frie...   \n",
       "14998  llama-2-70b-chat  [{'content': 'You will be given a definition o...   \n",
       "14999             gpt-4  [{'content': 'What's the resolution of a cat?'...   \n",
       "\n",
       "       rejected-rating       rejected-model  \n",
       "0                 3.75          ultralm-13b  \n",
       "1                 3.25           vicuna-33b  \n",
       "2                 1.75          ultralm-13b  \n",
       "3                 3.00          ultralm-13b  \n",
       "4                 4.50  falcon-40b-instruct  \n",
       "...                ...                  ...  \n",
       "14995             1.75      llama-2-7b-chat  \n",
       "14996             3.50      llama-2-7b-chat  \n",
       "14997             1.25      llama-2-7b-chat  \n",
       "14998             1.00           vicuna-33b  \n",
       "14999             4.00         wizardlm-70b  \n",
       "\n",
       "[15000 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df_clean.reset_index(drop=True)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['chosen'] = df_clean['chosen'].apply(lambda x: x[1]['content'])\n",
    "df_clean['rejected'] = df_clean['rejected'].apply(lambda x: x[1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to bring in the docs to filter before organizing and running stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pd.read_csv(\"UF10k_mixedbread_topics.csv\")\n",
    "docs = pd.read_csv(\"UF_mixedbread_docs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning\n",
    "docs['topic_id'] = docs['topic_id'].str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "docs['x_cord'] = docs['x_cord'].str.extract(r'(\\d+.\\d+)').astype(float)\n",
    "docs['y_cord'] = docs['y_cord'].str.extract(r'(\\d+.\\d+)').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging to get all the data in one place\n",
    "docs_and_topics = docs.merge(topics.drop(columns=['doc_id', 'topic_id']), on='content')\n",
    "docs_and_topics = docs_and_topics.drop(columns=['term_id', 'doc_id']).rename(columns={'10': 'metadata', 'content': 'prompt'})\n",
    "df_clean = df_clean.merge(docs_and_topics, on='prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>prompt</th>\n",
       "      <th>chosen</th>\n",
       "      <th>chosen-rating</th>\n",
       "      <th>chosen-model</th>\n",
       "      <th>rejected</th>\n",
       "      <th>rejected-rating</th>\n",
       "      <th>rejected-model</th>\n",
       "      <th>x_cord</th>\n",
       "      <th>y_cord</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>metadata</th>\n",
       "      <th>topic_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>Topics: Wound management for general practitio...</td>\n",
       "      <td>General practitioners play a vital role in the...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>Wound management is a crucial aspect of genera...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>ultralm-13b</td>\n",
       "      <td>0.915843</td>\n",
       "      <td>0.482842</td>\n",
       "      <td>22</td>\n",
       "      <td>[0.20282909274101257, -0.05036671459674835, -0...</td>\n",
       "      <td>('metadata', {'source': 'sharegpt', 'rating': ...</td>\n",
       "      <td>Childhood Stress and Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flan_v2_niv2</td>\n",
       "      <td>Part 1. Definition\\nIn this task, you are give...</td>\n",
       "      <td>Step 1: Identify the language of the post. The...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>Non-hateful\\n\\nExplanation: This post seems to...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>2.740021</td>\n",
       "      <td>4.862818</td>\n",
       "      <td>14</td>\n",
       "      <td>[0.06639007478952408, 0.23666216433048248, -0....</td>\n",
       "      <td>('metadata', {'source': 'flan_v2_niv2', 'ratin...</td>\n",
       "      <td>Analyzing Product Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>You will act as an voice changer. You will cha...</td>\n",
       "      <td>An umbrella has been brought by her on the way.</td>\n",
       "      <td>4.50</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>Alright, just let me know which form of voice ...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>ultralm-13b</td>\n",
       "      <td>2.045614</td>\n",
       "      <td>4.058925</td>\n",
       "      <td>15</td>\n",
       "      <td>[-0.4921853840351105, -0.1649392992258072, -0....</td>\n",
       "      <td>('metadata', {'source': 'sharegpt', 'rating': ...</td>\n",
       "      <td>Language Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ultrachat</td>\n",
       "      <td>Write a well-researched paper on the physiolog...</td>\n",
       "      <td>Title: The Physiological and Psychological Imp...</td>\n",
       "      <td>4.75</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>Title: The Physiological and Psychological Imp...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>ultralm-13b</td>\n",
       "      <td>1.698340</td>\n",
       "      <td>0.061782</td>\n",
       "      <td>8</td>\n",
       "      <td>[-0.30388227105140686, 0.15756076574325562, 0....</td>\n",
       "      <td>('metadata', {'source': 'ultrachat', 'rating':...</td>\n",
       "      <td>Healthy Lifestyle Exploration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ultrachat</td>\n",
       "      <td>Create a step-by-step recipe for making fluffy...</td>\n",
       "      <td>Of course, I'd be happy to help you with that!...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>Here is a step-by-step recipe for making fluff...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>falcon-40b-instruct</td>\n",
       "      <td>3.702293</td>\n",
       "      <td>1.716949</td>\n",
       "      <td>6</td>\n",
       "      <td>[-0.05435372143983841, 0.28580591082572937, -0...</td>\n",
       "      <td>('metadata', {'source': 'ultrachat', 'rating':...</td>\n",
       "      <td>Culinary Creations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>Transform is an emerging brand that delivers m...</td>\n",
       "      <td>Welcome to Transform, your go-to source for in...</td>\n",
       "      <td>4.75</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Sure, here's a possible description for the \"A...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>0.732869</td>\n",
       "      <td>1.959356</td>\n",
       "      <td>21</td>\n",
       "      <td>[-0.4771421253681183, -0.0352528840303421, -0....</td>\n",
       "      <td>('metadata', {'source': 'sharegpt', 'rating': ...</td>\n",
       "      <td>Marketing Strategy Platform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>evol_instruct</td>\n",
       "      <td>Using Python and the scikit-learn library, how...</td>\n",
       "      <td>Detecting sarcasm in text is a challenging tas...</td>\n",
       "      <td>4.75</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>Hello! As a helpful and respectful assistant, ...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>2.532706</td>\n",
       "      <td>5.040441</td>\n",
       "      <td>14</td>\n",
       "      <td>[0.3401801884174347, 0.21816378831863403, 0.02...</td>\n",
       "      <td>('metadata', {'source': 'evol_instruct', 'rati...</td>\n",
       "      <td>Analyzing Product Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>flan_v2_cot</td>\n",
       "      <td>[QUESTION] If \"Two kids stepping stones over t...</td>\n",
       "      <td>Yes, the premise mentions pink plaid pants and...</td>\n",
       "      <td>4.75</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Confidence: 80%\\n\\nYou have provided several s...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>3.797116</td>\n",
       "      <td>0.511288</td>\n",
       "      <td>18</td>\n",
       "      <td>[0.39390242099761963, 0.10773289203643799, -0....</td>\n",
       "      <td>('metadata', {'source': 'flan_v2_cot', 'rating...</td>\n",
       "      <td>Gender and Clothing Perceptions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10206</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>Write me a letter asking my friend Dan what he...</td>\n",
       "      <td>Dear Dan,\\n\\nWe hope this letter finds you wel...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>ultralm-13b</td>\n",
       "      <td>I cannot fulfill your request as it goes again...</td>\n",
       "      <td>1.25</td>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>0.873350</td>\n",
       "      <td>3.242940</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.7983337640762329, -0.37210243940353394, 0.5...</td>\n",
       "      <td>('metadata', {'source': 'sharegpt', 'rating': ...</td>\n",
       "      <td>Cultural Expression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10207</th>\n",
       "      <td>false_qa</td>\n",
       "      <td>What's the resolution of a cat?</td>\n",
       "      <td>As an AI, I assume you are asking about a cat'...</td>\n",
       "      <td>4.25</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>As an AI, I don't have the capability to deter...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>0.756816</td>\n",
       "      <td>1.959702</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.114014632999897, -0.06832381337881088, 0.15...</td>\n",
       "      <td>('metadata', {'source': 'false_qa', 'rating': ...</td>\n",
       "      <td>Creative Writing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10208 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              source                                             prompt  \\\n",
       "0           sharegpt  Topics: Wound management for general practitio...   \n",
       "1       flan_v2_niv2  Part 1. Definition\\nIn this task, you are give...   \n",
       "2           sharegpt  You will act as an voice changer. You will cha...   \n",
       "3          ultrachat  Write a well-researched paper on the physiolog...   \n",
       "4          ultrachat  Create a step-by-step recipe for making fluffy...   \n",
       "...              ...                                                ...   \n",
       "10203       sharegpt  Transform is an emerging brand that delivers m...   \n",
       "10204  evol_instruct  Using Python and the scikit-learn library, how...   \n",
       "10205    flan_v2_cot  [QUESTION] If \"Two kids stepping stones over t...   \n",
       "10206       sharegpt  Write me a letter asking my friend Dan what he...   \n",
       "10207       false_qa                    What's the resolution of a cat?   \n",
       "\n",
       "                                                  chosen  chosen-rating  \\\n",
       "0      General practitioners play a vital role in the...           5.00   \n",
       "1      Step 1: Identify the language of the post. The...           4.50   \n",
       "2        An umbrella has been brought by her on the way.           4.50   \n",
       "3      Title: The Physiological and Psychological Imp...           4.75   \n",
       "4      Of course, I'd be happy to help you with that!...           5.00   \n",
       "...                                                  ...            ...   \n",
       "10203  Welcome to Transform, your go-to source for in...           4.75   \n",
       "10204  Detecting sarcasm in text is a challenging tas...           4.75   \n",
       "10205  Yes, the premise mentions pink plaid pants and...           4.75   \n",
       "10206  Dear Dan,\\n\\nWe hope this letter finds you wel...           4.50   \n",
       "10207  As an AI, I assume you are asking about a cat'...           4.25   \n",
       "\n",
       "          chosen-model                                           rejected  \\\n",
       "0         wizardlm-70b  Wound management is a crucial aspect of genera...   \n",
       "1         wizardlm-70b  Non-hateful\\n\\nExplanation: This post seems to...   \n",
       "2         wizardlm-13b  Alright, just let me know which form of voice ...   \n",
       "3         wizardlm-13b  Title: The Physiological and Psychological Imp...   \n",
       "4      llama-2-7b-chat  Here is a step-by-step recipe for making fluff...   \n",
       "...                ...                                                ...   \n",
       "10203    gpt-3.5-turbo  Sure, here's a possible description for the \"A...   \n",
       "10204     wizardlm-13b  Hello! As a helpful and respectful assistant, ...   \n",
       "10205    gpt-3.5-turbo  Confidence: 80%\\n\\nYou have provided several s...   \n",
       "10206      ultralm-13b  I cannot fulfill your request as it goes again...   \n",
       "10207            gpt-4  As an AI, I don't have the capability to deter...   \n",
       "\n",
       "       rejected-rating       rejected-model    x_cord    y_cord  topic_id  \\\n",
       "0                 3.75          ultralm-13b  0.915843  0.482842        22   \n",
       "1                 3.25           vicuna-33b  2.740021  4.862818        14   \n",
       "2                 1.75          ultralm-13b  2.045614  4.058925        15   \n",
       "3                 3.00          ultralm-13b  1.698340  0.061782         8   \n",
       "4                 4.50  falcon-40b-instruct  3.702293  1.716949         6   \n",
       "...                ...                  ...       ...       ...       ...   \n",
       "10203             4.00     llama-2-70b-chat  0.732869  1.959356        21   \n",
       "10204             4.00     llama-2-13b-chat  2.532706  5.040441        14   \n",
       "10205             1.75      llama-2-7b-chat  3.797116  0.511288        18   \n",
       "10206             1.25      llama-2-7b-chat  0.873350  3.242940         1   \n",
       "10207             4.00         wizardlm-70b  0.756816  1.959702        10   \n",
       "\n",
       "                                              embeddings  \\\n",
       "0      [0.20282909274101257, -0.05036671459674835, -0...   \n",
       "1      [0.06639007478952408, 0.23666216433048248, -0....   \n",
       "2      [-0.4921853840351105, -0.1649392992258072, -0....   \n",
       "3      [-0.30388227105140686, 0.15756076574325562, 0....   \n",
       "4      [-0.05435372143983841, 0.28580591082572937, -0...   \n",
       "...                                                  ...   \n",
       "10203  [-0.4771421253681183, -0.0352528840303421, -0....   \n",
       "10204  [0.3401801884174347, 0.21816378831863403, 0.02...   \n",
       "10205  [0.39390242099761963, 0.10773289203643799, -0....   \n",
       "10206  [0.7983337640762329, -0.37210243940353394, 0.5...   \n",
       "10207  [0.114014632999897, -0.06832381337881088, 0.15...   \n",
       "\n",
       "                                                metadata  \\\n",
       "0      ('metadata', {'source': 'sharegpt', 'rating': ...   \n",
       "1      ('metadata', {'source': 'flan_v2_niv2', 'ratin...   \n",
       "2      ('metadata', {'source': 'sharegpt', 'rating': ...   \n",
       "3      ('metadata', {'source': 'ultrachat', 'rating':...   \n",
       "4      ('metadata', {'source': 'ultrachat', 'rating':...   \n",
       "...                                                  ...   \n",
       "10203  ('metadata', {'source': 'sharegpt', 'rating': ...   \n",
       "10204  ('metadata', {'source': 'evol_instruct', 'rati...   \n",
       "10205  ('metadata', {'source': 'flan_v2_cot', 'rating...   \n",
       "10206  ('metadata', {'source': 'sharegpt', 'rating': ...   \n",
       "10207  ('metadata', {'source': 'false_qa', 'rating': ...   \n",
       "\n",
       "                            topic_name  \n",
       "0          Childhood Stress and Health  \n",
       "1          Analyzing Product Sentiment  \n",
       "2                    Language Analysis  \n",
       "3        Healthy Lifestyle Exploration  \n",
       "4                   Culinary Creations  \n",
       "...                                ...  \n",
       "10203      Marketing Strategy Platform  \n",
       "10204      Analyzing Product Sentiment  \n",
       "10205  Gender and Clothing Perceptions  \n",
       "10206              Cultural Expression  \n",
       "10207                 Creative Writing  \n",
       "\n",
       "[10208 rows x 14 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we need put all the responses together, regradless of whether they are rejected or accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reject = df_clean.iloc[:, [0 , 1, 5, 6, 7]]\n",
    "df_accept = df_clean.iloc[:, [0, 1, 2, 3, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reject = df_reject.rename(columns={'rejected' : 'response', 'rejected-rating' : 'rating', 'rejected-model' : 'model'})\n",
    "df_reject['chosen'] = 0\n",
    "df_accept = df_accept.rename(columns={'chosen' : 'response', 'chosen-rating': 'rating', 'chosen-model' : 'model'})\n",
    "df_accept['chosen'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_accept, df_reject]\n",
    "\n",
    "#put them all together\n",
    "\n",
    "df_all = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>rating</th>\n",
       "      <th>model</th>\n",
       "      <th>chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>Topics: Wound management for general practitio...</td>\n",
       "      <td>General practitioners play a vital role in the...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flan_v2_niv2</td>\n",
       "      <td>Part 1. Definition\\nIn this task, you are give...</td>\n",
       "      <td>Step 1: Identify the language of the post. The...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>You will act as an voice changer. You will cha...</td>\n",
       "      <td>An umbrella has been brought by her on the way.</td>\n",
       "      <td>4.50</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ultrachat</td>\n",
       "      <td>Write a well-researched paper on the physiolog...</td>\n",
       "      <td>Title: The Physiological and Psychological Imp...</td>\n",
       "      <td>4.75</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ultrachat</td>\n",
       "      <td>Create a step-by-step recipe for making fluffy...</td>\n",
       "      <td>Of course, I'd be happy to help you with that!...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>Transform is an emerging brand that delivers m...</td>\n",
       "      <td>Sure, here's a possible description for the \"A...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10204</th>\n",
       "      <td>evol_instruct</td>\n",
       "      <td>Using Python and the scikit-learn library, how...</td>\n",
       "      <td>Hello! As a helpful and respectful assistant, ...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10205</th>\n",
       "      <td>flan_v2_cot</td>\n",
       "      <td>[QUESTION] If \"Two kids stepping stones over t...</td>\n",
       "      <td>Confidence: 80%\\n\\nYou have provided several s...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10206</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>Write me a letter asking my friend Dan what he...</td>\n",
       "      <td>I cannot fulfill your request as it goes again...</td>\n",
       "      <td>1.25</td>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10207</th>\n",
       "      <td>false_qa</td>\n",
       "      <td>What's the resolution of a cat?</td>\n",
       "      <td>As an AI, I don't have the capability to deter...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20416 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              source                                             prompt  \\\n",
       "0           sharegpt  Topics: Wound management for general practitio...   \n",
       "1       flan_v2_niv2  Part 1. Definition\\nIn this task, you are give...   \n",
       "2           sharegpt  You will act as an voice changer. You will cha...   \n",
       "3          ultrachat  Write a well-researched paper on the physiolog...   \n",
       "4          ultrachat  Create a step-by-step recipe for making fluffy...   \n",
       "...              ...                                                ...   \n",
       "10203       sharegpt  Transform is an emerging brand that delivers m...   \n",
       "10204  evol_instruct  Using Python and the scikit-learn library, how...   \n",
       "10205    flan_v2_cot  [QUESTION] If \"Two kids stepping stones over t...   \n",
       "10206       sharegpt  Write me a letter asking my friend Dan what he...   \n",
       "10207       false_qa                    What's the resolution of a cat?   \n",
       "\n",
       "                                                response  rating  \\\n",
       "0      General practitioners play a vital role in the...    5.00   \n",
       "1      Step 1: Identify the language of the post. The...    4.50   \n",
       "2        An umbrella has been brought by her on the way.    4.50   \n",
       "3      Title: The Physiological and Psychological Imp...    4.75   \n",
       "4      Of course, I'd be happy to help you with that!...    5.00   \n",
       "...                                                  ...     ...   \n",
       "10203  Sure, here's a possible description for the \"A...    4.00   \n",
       "10204  Hello! As a helpful and respectful assistant, ...    4.00   \n",
       "10205  Confidence: 80%\\n\\nYou have provided several s...    1.75   \n",
       "10206  I cannot fulfill your request as it goes again...    1.25   \n",
       "10207  As an AI, I don't have the capability to deter...    4.00   \n",
       "\n",
       "                  model  chosen  \n",
       "0          wizardlm-70b       1  \n",
       "1          wizardlm-70b       1  \n",
       "2          wizardlm-13b       1  \n",
       "3          wizardlm-13b       1  \n",
       "4       llama-2-7b-chat       1  \n",
       "...                 ...     ...  \n",
       "10203  llama-2-70b-chat       0  \n",
       "10204  llama-2-13b-chat       0  \n",
       "10205   llama-2-7b-chat       0  \n",
       "10206   llama-2-7b-chat       0  \n",
       "10207      wizardlm-70b       0  \n",
       "\n",
       "[20416 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting metadata back in:\n",
    "df_all = df_all.merge(df_clean.loc[:, ['prompt', 'x_cord', 'y_cord','topic_id', 'embeddings', 'metadata', 'topic_name']], on='prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix them up \n",
    "df_all = df_all.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for some reason these rows don't work, idk why. Your dataset might not run in to this issue\n",
    "bads = [5230, 19157]\n",
    "\n",
    "df_all = df_all.drop(bads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting statistics form each of the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get text statisitsics for each response \n",
    "\n",
    "# NB! This takes forever to run so try to run it only once\n",
    "\n",
    "for i, row in df_all.iterrows():\n",
    "    #Make each into a SpaCy doc\n",
    "\n",
    "    response = make_spacy_doc(row['response'], lang='en_core_web_sm')\n",
    "    \n",
    "    #Basics\n",
    "\n",
    "    df_all.loc[i, 'n_sents'] = text_stats.basics.n_sents(response)\n",
    "\n",
    "    df_all.loc[i, 'n_words'] = text_stats.basics.n_words(response)\n",
    "\n",
    "    df_all.loc[i, 'n_uniquewords'] = text_stats.basics.n_unique_words(response)\n",
    "\n",
    "    df_all.loc[i, 'n_chars'] = text_stats.basics.n_chars(response)\n",
    "\n",
    "    df_all.loc[i, 'n_longwords'] = text_stats.basics.n_long_words(response)\n",
    "\n",
    "    df_all.loc[i, 'n_sylsprword'] = text_stats.basics.n_syllables(response)\n",
    "\n",
    "    df_all.loc[i, 'n_monosylwords'] = text_stats.basics.n_monosyllable_words(response)\n",
    "\n",
    "    df_all.loc[i, 'n_polysylwords'] = text_stats.basics.n_polysyllable_words(response)\n",
    "\n",
    "    df_all.loc[i, 'entropy'] = text_stats.basics.entropy(response)\n",
    "\n",
    "    #Lexical Diversity\n",
    "\n",
    "    df_all.loc[i, 'ttr'] = text_stats.diversity.ttr(response)\n",
    "\n",
    "    df_all.loc[i, 'log_ttr'] = text_stats.diversity.log_ttr(response)\n",
    "\n",
    "    df_all.loc[i, 'seg_ttr'] = text_stats.diversity.segmented_ttr(response)\n",
    "\n",
    "    df_all.loc[i, 'mtld'] = text_stats.diversity.mtld(response)\n",
    "\n",
    "    df_all.loc[i, 'hdd'] = text_stats.diversity.hdd(response)\n",
    "    \n",
    "    #Readability\n",
    "\n",
    "    df_all.loc[i, 'flesch_score'] = text_stats.readability.flesch_reading_ease(response) \n",
    "\n",
    "    df_all.loc[i, 'flesch_grade'] = text_stats.readability.flesch_kincaid_grade_level(response)\n",
    "\n",
    "    df_all.loc[i, 'gunning_fog'] = text_stats.readability.gunning_fog_index(response) \n",
    "\n",
    "    df_all.loc[i, 'coleman_liau'] = text_stats.readability.coleman_liau_index(response) \n",
    "\n",
    "    df_all.loc[i, 'automated_readability'] = text_stats.readability.automated_readability_index(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_checkpoint  = df_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reordering for easier indexing\n",
    "cols = df_all.columns.tolist()\n",
    "cols = ['source',\n",
    " 'prompt',\n",
    " 'response',\n",
    " 'model',\n",
    " 'chosen',\n",
    " 'rating',\n",
    " 'n_sents',\n",
    " 'n_words',\n",
    " 'n_uniquewords',\n",
    " 'n_chars',\n",
    " 'n_longwords',\n",
    " 'n_sylsprword',\n",
    " 'n_monosylwords',\n",
    " 'n_polysylwords',\n",
    " 'entropy',\n",
    " 'ttr',\n",
    " 'log_ttr',\n",
    " 'seg_ttr',\n",
    " 'mtld',\n",
    " 'hdd',\n",
    " 'flesch_score',\n",
    " 'flesch_grade',\n",
    " 'gunning_fog',\n",
    " 'coleman_liau',\n",
    " 'automated_readability',\n",
    " 'x_cord',\n",
    " 'y_cord',\n",
    " 'topic_id',\n",
    " 'embeddings',\n",
    " 'metadata',\n",
    " 'topic_name']\n",
    "\n",
    "df_all = df_all[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(\"Accepted_Rejected_with_scores.csv\")\n",
    "\n",
    "# # df_all = pd.read_csv(\"Accepted_Rejected_with_scores.csv\")\n",
    "\n",
    "# df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_only = df_all.iloc[:, 4:-6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicators of 'Accepted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "continuous_vars = stats_only.columns[1:]\n",
    "dummy_vars = [stats_only.columns[0]]\n",
    "\n",
    "index = pd.MultiIndex.from_product([continuous_vars])\n",
    "\n",
    "corr_df = pd.DataFrame(index=continuous_vars, columns=dummy_vars)\n",
    "\n",
    "for dummy in dummy_vars:\n",
    "    for continuous in continuous_vars:\n",
    "        corr, p_value = pointbiserialr(stats_only[continuous], stats_only[dummy])\n",
    "        results[f'{continuous} & {dummy}'] = (corr, p_value)\n",
    "        corr_df.loc[continuous, dummy] = corr\n",
    "        \n",
    "\n",
    "corr_df = corr_df.apply(pd.to_numeric)\n",
    "\n",
    "pvalues = []\n",
    "for i in results.values():\n",
    "    pvalues.append((i[1]))\n",
    "\n",
    "corr_df['p_values'] = pvalues\n",
    "\n",
    "corr_df = corr_df.rename(columns={'chosen': 'PB_Correlation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need a standardized way of assesing variance of metrics\n",
    "\n",
    "def coefficient_of_variation(series):\n",
    "    return series.std() / series.mean()\n",
    "\n",
    "cv = stats_only.iloc[:, 1:].apply(coefficient_of_variation)\n",
    "\n",
    "corr_df['coef_of_variation'] = cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PB_Correlation</th>\n",
       "      <th>p_values</th>\n",
       "      <th>coef_of_variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>0.614510</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.243758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_uniquewords</th>\n",
       "      <td>0.182092</td>\n",
       "      <td>1.064511e-151</td>\n",
       "      <td>0.756658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_longwords</th>\n",
       "      <td>0.175959</td>\n",
       "      <td>1.251788e-141</td>\n",
       "      <td>1.012037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_chars</th>\n",
       "      <td>0.174384</td>\n",
       "      <td>4.207479e-139</td>\n",
       "      <td>0.919935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_sylsprword</th>\n",
       "      <td>0.172199</td>\n",
       "      <td>1.232727e-135</td>\n",
       "      <td>0.918244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_polysylwords</th>\n",
       "      <td>0.166823</td>\n",
       "      <td>2.638746e-127</td>\n",
       "      <td>1.128188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_words</th>\n",
       "      <td>0.165324</td>\n",
       "      <td>4.957085e-125</td>\n",
       "      <td>0.882359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_sents</th>\n",
       "      <td>0.158025</td>\n",
       "      <td>2.860982e-114</td>\n",
       "      <td>0.959185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_monosylwords</th>\n",
       "      <td>0.150066</td>\n",
       "      <td>4.091511e-103</td>\n",
       "      <td>0.873543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>0.118253</td>\n",
       "      <td>1.792173e-64</td>\n",
       "      <td>0.296626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coleman_liau</th>\n",
       "      <td>0.050558</td>\n",
       "      <td>4.907643e-13</td>\n",
       "      <td>0.939049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>automated_readability</th>\n",
       "      <td>0.038548</td>\n",
       "      <td>3.601281e-08</td>\n",
       "      <td>0.788087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flesch_grade</th>\n",
       "      <td>0.036130</td>\n",
       "      <td>2.423811e-07</td>\n",
       "      <td>0.596011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gunning_fog</th>\n",
       "      <td>0.032234</td>\n",
       "      <td>4.096916e-06</td>\n",
       "      <td>0.481790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_ttr</th>\n",
       "      <td>-0.014892</td>\n",
       "      <td>3.335584e-02</td>\n",
       "      <td>0.189939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hdd</th>\n",
       "      <td>-0.022535</td>\n",
       "      <td>1.281882e-03</td>\n",
       "      <td>0.107014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtld</th>\n",
       "      <td>-0.030062</td>\n",
       "      <td>1.740416e-05</td>\n",
       "      <td>4.651651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_ttr</th>\n",
       "      <td>-0.032428</td>\n",
       "      <td>3.584195e-06</td>\n",
       "      <td>0.125137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flesch_score</th>\n",
       "      <td>-0.049224</td>\n",
       "      <td>1.965818e-12</td>\n",
       "      <td>0.385367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ttr</th>\n",
       "      <td>-0.113303</td>\n",
       "      <td>2.641493e-59</td>\n",
       "      <td>0.303282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       PB_Correlation       p_values  coef_of_variation\n",
       "rating                       0.614510   0.000000e+00           0.243758\n",
       "n_uniquewords                0.182092  1.064511e-151           0.756658\n",
       "n_longwords                  0.175959  1.251788e-141           1.012037\n",
       "n_chars                      0.174384  4.207479e-139           0.919935\n",
       "n_sylsprword                 0.172199  1.232727e-135           0.918244\n",
       "n_polysylwords               0.166823  2.638746e-127           1.128188\n",
       "n_words                      0.165324  4.957085e-125           0.882359\n",
       "n_sents                      0.158025  2.860982e-114           0.959185\n",
       "n_monosylwords               0.150066  4.091511e-103           0.873543\n",
       "entropy                      0.118253   1.792173e-64           0.296626\n",
       "coleman_liau                 0.050558   4.907643e-13           0.939049\n",
       "automated_readability        0.038548   3.601281e-08           0.788087\n",
       "flesch_grade                 0.036130   2.423811e-07           0.596011\n",
       "gunning_fog                  0.032234   4.096916e-06           0.481790\n",
       "log_ttr                     -0.014892   3.335584e-02           0.189939\n",
       "hdd                         -0.022535   1.281882e-03           0.107014\n",
       "mtld                        -0.030062   1.740416e-05           4.651651\n",
       "seg_ttr                     -0.032428   3.584195e-06           0.125137\n",
       "flesch_score                -0.049224   1.965818e-12           0.385367\n",
       "ttr                         -0.113303   2.641493e-59           0.303282"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df.sort_values(by=['PB_Correlation', 'coef_of_variation', 'p_values'], ascending=[False, False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistically Significant metrics for 'Accepted' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PB_Correlation</th>\n",
       "      <th>p_values</th>\n",
       "      <th>coef_of_variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>0.614510</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.243758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_uniquewords</th>\n",
       "      <td>0.182092</td>\n",
       "      <td>1.064511e-151</td>\n",
       "      <td>0.756658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_longwords</th>\n",
       "      <td>0.175959</td>\n",
       "      <td>1.251788e-141</td>\n",
       "      <td>1.012037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_chars</th>\n",
       "      <td>0.174384</td>\n",
       "      <td>4.207479e-139</td>\n",
       "      <td>0.919935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_sylsprword</th>\n",
       "      <td>0.172199</td>\n",
       "      <td>1.232727e-135</td>\n",
       "      <td>0.918244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_polysylwords</th>\n",
       "      <td>0.166823</td>\n",
       "      <td>2.638746e-127</td>\n",
       "      <td>1.128188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_words</th>\n",
       "      <td>0.165324</td>\n",
       "      <td>4.957085e-125</td>\n",
       "      <td>0.882359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_sents</th>\n",
       "      <td>0.158025</td>\n",
       "      <td>2.860982e-114</td>\n",
       "      <td>0.959185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_monosylwords</th>\n",
       "      <td>0.150066</td>\n",
       "      <td>4.091511e-103</td>\n",
       "      <td>0.873543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entropy</th>\n",
       "      <td>0.118253</td>\n",
       "      <td>1.792173e-64</td>\n",
       "      <td>0.296626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coleman_liau</th>\n",
       "      <td>0.050558</td>\n",
       "      <td>4.907643e-13</td>\n",
       "      <td>0.939049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>automated_readability</th>\n",
       "      <td>0.038548</td>\n",
       "      <td>3.601281e-08</td>\n",
       "      <td>0.788087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flesch_grade</th>\n",
       "      <td>0.036130</td>\n",
       "      <td>2.423811e-07</td>\n",
       "      <td>0.596011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gunning_fog</th>\n",
       "      <td>0.032234</td>\n",
       "      <td>4.096916e-06</td>\n",
       "      <td>0.481790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_ttr</th>\n",
       "      <td>-0.014892</td>\n",
       "      <td>3.335584e-02</td>\n",
       "      <td>0.189939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hdd</th>\n",
       "      <td>-0.022535</td>\n",
       "      <td>1.281882e-03</td>\n",
       "      <td>0.107014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtld</th>\n",
       "      <td>-0.030062</td>\n",
       "      <td>1.740416e-05</td>\n",
       "      <td>4.651651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_ttr</th>\n",
       "      <td>-0.032428</td>\n",
       "      <td>3.584195e-06</td>\n",
       "      <td>0.125137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flesch_score</th>\n",
       "      <td>-0.049224</td>\n",
       "      <td>1.965818e-12</td>\n",
       "      <td>0.385367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ttr</th>\n",
       "      <td>-0.113303</td>\n",
       "      <td>2.641493e-59</td>\n",
       "      <td>0.303282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       PB_Correlation       p_values  coef_of_variation\n",
       "rating                       0.614510   0.000000e+00           0.243758\n",
       "n_uniquewords                0.182092  1.064511e-151           0.756658\n",
       "n_longwords                  0.175959  1.251788e-141           1.012037\n",
       "n_chars                      0.174384  4.207479e-139           0.919935\n",
       "n_sylsprword                 0.172199  1.232727e-135           0.918244\n",
       "n_polysylwords               0.166823  2.638746e-127           1.128188\n",
       "n_words                      0.165324  4.957085e-125           0.882359\n",
       "n_sents                      0.158025  2.860982e-114           0.959185\n",
       "n_monosylwords               0.150066  4.091511e-103           0.873543\n",
       "entropy                      0.118253   1.792173e-64           0.296626\n",
       "coleman_liau                 0.050558   4.907643e-13           0.939049\n",
       "automated_readability        0.038548   3.601281e-08           0.788087\n",
       "flesch_grade                 0.036130   2.423811e-07           0.596011\n",
       "gunning_fog                  0.032234   4.096916e-06           0.481790\n",
       "log_ttr                     -0.014892   3.335584e-02           0.189939\n",
       "hdd                         -0.022535   1.281882e-03           0.107014\n",
       "mtld                        -0.030062   1.740416e-05           4.651651\n",
       "seg_ttr                     -0.032428   3.584195e-06           0.125137\n",
       "flesch_score                -0.049224   1.965818e-12           0.385367\n",
       "ttr                         -0.113303   2.641493e-59           0.303282"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df[corr_df['p_values'] <= 0.05].sort_values(by=['PB_Correlation', 'coef_of_variation'], ascending=[False, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the z-score for all the metrics. \n",
    "for col in stats_only.columns:\n",
    "    df_all.loc[:, col + '_z_score'] = zscore(df_all.loc[:, col])\n",
    "\n",
    "\n",
    "z_score_cols = df_all.columns[32: ]\n",
    "relevant_z_scores = ['n_uniquewords_z_score', 'n_longwords_z_score', 'n_chars_z_score', 'n_sylsprword_z_score', \n",
    "                     'n_polysylwords_z_score', 'n_words_z_score', 'n_sents_z_score', 'n_monosylwords_z_score',\n",
    "                     'entropy_z_score', 'coleman_liau_z_score', 'automated_readability_z_score', 'flesch_score_z_score', 'gunning_fog_z_score']\n",
    "\n",
    "df_all.to_csv(\"Accepted_Rejected_with_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB! You need to remove these two rows because they throw an error when you try to match them with a score, because they are the ones we took out when converting to spacy doc, since spacy cannot convert empty strings. I probably should have done this earlier but oh well. They are found by running the loops below\n",
    "df_clean = df_clean.drop([2776, 3482]).reset_index(drop=True)\n",
    "\n",
    "# for i in range(len(df_clean)):\n",
    "#     try:\n",
    "#         x = np.where(chosen_response_metric_pairs['response'] == df_clean['chosen'][i])[0][0]\n",
    "#     except:\n",
    "#         print(i)\n",
    "\n",
    "# for i in range(len(df_clean)):\n",
    "#     try:\n",
    "#         x = np.where(rejected_response_metric_pairs['response'] == df_clean['rejected'][i])[0][0]\n",
    "#     except:\n",
    "#         print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[:, 'linear_metric'] = df_all.loc[:, relevant_z_scores].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy for editing\n",
    "df_linear = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviaton</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accepted</td>\n",
       "      <td>1.535089</td>\n",
       "      <td>9.609459</td>\n",
       "      <td>92.341695</td>\n",
       "      <td>94.443280</td>\n",
       "      <td>-20.165456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>-1.535390</td>\n",
       "      <td>8.369840</td>\n",
       "      <td>70.054229</td>\n",
       "      <td>58.577392</td>\n",
       "      <td>-20.165456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Group      Mean  Standard Deviaton   Variance        Max        Min\n",
       "0  Accepted  1.535089           9.609459  92.341695  94.443280 -20.165456\n",
       "1  Rejected -1.535390           8.369840  70.054229  58.577392 -20.165456"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_subset = df_all[df_all['chosen'] == 1]\n",
    "rejected_subset = df_all[df_all['chosen'] == 0]\n",
    "\n",
    "Linear_chosen_response_metric_pairs = pd.DataFrame({'response': chosen_subset.loc[:, 'response'], 'score': chosen_subset.loc[:, 'linear_metric']}).reset_index(drop=True)\n",
    "Linear_rejected_response_metric_pairs = pd.DataFrame({'response': rejected_subset.loc[:, 'response'], 'score': rejected_subset.loc[:, 'linear_metric']}).reset_index(drop=True)\n",
    "\n",
    "#Let's check out the stats on the metric real quick:\n",
    "Linear_metric_distribution = pd.DataFrame({'Group': ['Accepted', 'Rejected'], \n",
    "                        'Mean' : [Linear_chosen_response_metric_pairs['score'].mean(), Linear_rejected_response_metric_pairs['score'].mean()], \n",
    "                        'Standard Deviaton': [np.std(Linear_chosen_response_metric_pairs['score']), np.std(Linear_rejected_response_metric_pairs['score'])],\n",
    "                        'Variance': [np.var(Linear_chosen_response_metric_pairs['score']), np.var(Linear_rejected_response_metric_pairs['score'])],\n",
    "                        'Max': [Linear_chosen_response_metric_pairs['score'].max(), Linear_rejected_response_metric_pairs['score'].max()],\n",
    "                        'Min': [Linear_chosen_response_metric_pairs['score'].min(), Linear_rejected_response_metric_pairs['score'].min()]}) \n",
    "\n",
    "Linear_metric_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the metrics in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize columns\n",
    "df_linear['accepted_linear_metric'] = None\n",
    "df_linear['rejected_linear_metric'] = None\n",
    "\n",
    "#cycle through the subsets to get the scores and match them to their respective rows given the pairs in df_clean\n",
    "for i in range(len(df_clean)):\n",
    "    df_linear.iloc[i, df_linear.columns.get_loc('accepted_linear_metric')]= Linear_chosen_response_metric_pairs.iloc[np.where(Linear_chosen_response_metric_pairs['response'] == df_linear['chosen'][i])[0][0], -1]\n",
    "    df_linear.iloc[i, df_linear.columns.get_loc('rejected_linear_metric')] = Linear_rejected_response_metric_pairs.iloc[np.where(Linear_rejected_response_metric_pairs['response'] == df_linear['rejected'][i])[0][0], -1]\n",
    "\n",
    "df_linear['diff_linear_metric'] = df_linear['accepted_linear_metric'] - df_linear['rejected_linear_metric']\n",
    "df_linear.to_csv(\"linear_metric_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric Mean - actually can't do this because there are negative numbers in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gmean_linear = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmeans = gmean(df_all.loc[:, relevant_z_scores]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36082393, 0.33315898, 0.36894024, 0.36676704, 0.30441279,\n",
       "       0.37709697, 0.32685727, 0.3550817 , 0.21994893, 0.06290751,\n",
       "       0.10475022, 0.17203504, 0.15986658])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>model</th>\n",
       "      <th>chosen</th>\n",
       "      <th>rating</th>\n",
       "      <th>n_sents</th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_uniquewords</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>...</th>\n",
       "      <th>hdd_z_score</th>\n",
       "      <th>flesch_score_z_score</th>\n",
       "      <th>flesch_grade_z_score</th>\n",
       "      <th>gunning_fog_z_score</th>\n",
       "      <th>coleman_liau_z_score</th>\n",
       "      <th>automated_readability_z_score</th>\n",
       "      <th>linear_metric</th>\n",
       "      <th>PCA1</th>\n",
       "      <th>weighted_pca</th>\n",
       "      <th>gmean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evol_instruct</td>\n",
       "      <td>Which word does not belong in the following gr...</td>\n",
       "      <td>Kettle does not belong in the group as it is a...</td>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.580441</td>\n",
       "      <td>0.793446</td>\n",
       "      <td>-0.155766</td>\n",
       "      <td>-0.326385</td>\n",
       "      <td>-0.467108</td>\n",
       "      <td>-0.143045</td>\n",
       "      <td>-8.507311</td>\n",
       "      <td>-2.935682</td>\n",
       "      <td>-1.893228</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ultrachat</td>\n",
       "      <td>In what ways has technology changed the way in...</td>\n",
       "      <td>I do not have personal views or opinions. howe...</td>\n",
       "      <td>ultralm-65b</td>\n",
       "      <td>0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>13.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185218</td>\n",
       "      <td>-0.306184</td>\n",
       "      <td>0.331115</td>\n",
       "      <td>0.290942</td>\n",
       "      <td>0.333853</td>\n",
       "      <td>0.312785</td>\n",
       "      <td>3.848131</td>\n",
       "      <td>1.195098</td>\n",
       "      <td>0.847282</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flan_v2_niv2</td>\n",
       "      <td>Detailed Instructions: In this task you are gi...</td>\n",
       "      <td>Pangaea and Gondwana were two supercontinents ...</td>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>0</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.654118</td>\n",
       "      <td>-0.340191</td>\n",
       "      <td>0.328534</td>\n",
       "      <td>0.219528</td>\n",
       "      <td>0.432542</td>\n",
       "      <td>0.375533</td>\n",
       "      <td>-3.735004</td>\n",
       "      <td>-1.244462</td>\n",
       "      <td>-0.547941</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ultrachat</td>\n",
       "      <td>What are the best snorkeling spots in Hawaii?</td>\n",
       "      <td>Hawaii is famous for its breathtaking underwat...</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281771</td>\n",
       "      <td>0.037216</td>\n",
       "      <td>-0.080562</td>\n",
       "      <td>-0.218502</td>\n",
       "      <td>0.221718</td>\n",
       "      <td>0.010123</td>\n",
       "      <td>9.132258</td>\n",
       "      <td>2.909264</td>\n",
       "      <td>1.700674</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>false_qa</td>\n",
       "      <td>Why do anaerobic bacteria prefer an environmen...</td>\n",
       "      <td>Anaerobic bacteria do not prefer an environmen...</td>\n",
       "      <td>mpt-30b-chat</td>\n",
       "      <td>1</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.793461</td>\n",
       "      <td>-0.399084</td>\n",
       "      <td>0.384574</td>\n",
       "      <td>0.457682</td>\n",
       "      <td>0.156561</td>\n",
       "      <td>0.140014</td>\n",
       "      <td>-4.842261</td>\n",
       "      <td>-1.526221</td>\n",
       "      <td>-0.758836</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20411</th>\n",
       "      <td>flan_v2_niv2</td>\n",
       "      <td>You will be given a sentence that describes a ...</td>\n",
       "      <td>Could you please verify the categories and the...</td>\n",
       "      <td>falcon-40b-instruct</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518269</td>\n",
       "      <td>-0.307540</td>\n",
       "      <td>0.094814</td>\n",
       "      <td>0.373319</td>\n",
       "      <td>0.428784</td>\n",
       "      <td>0.145619</td>\n",
       "      <td>-7.026232</td>\n",
       "      <td>-2.289629</td>\n",
       "      <td>-1.185295</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20412</th>\n",
       "      <td>evol_instruct</td>\n",
       "      <td>How can I modify the existing C# code to also ...</td>\n",
       "      <td>To modify the existing code to calculate the e...</td>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.361023</td>\n",
       "      <td>-1.138155</td>\n",
       "      <td>1.266837</td>\n",
       "      <td>1.272938</td>\n",
       "      <td>0.551847</td>\n",
       "      <td>0.959843</td>\n",
       "      <td>10.339279</td>\n",
       "      <td>3.359946</td>\n",
       "      <td>2.371094</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20413</th>\n",
       "      <td>flan_v2_niv2</td>\n",
       "      <td>Find the movie name from the given conversatio...</td>\n",
       "      <td>The Lion King</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.035658</td>\n",
       "      <td>1.105190</td>\n",
       "      <td>-1.423146</td>\n",
       "      <td>-1.865734</td>\n",
       "      <td>-1.503475</td>\n",
       "      <td>-1.596003</td>\n",
       "      <td>-14.783595</td>\n",
       "      <td>-4.272149</td>\n",
       "      <td>-3.193378</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20414</th>\n",
       "      <td>sharegpt</td>\n",
       "      <td>Create a slack conversation between 4 people, ...</td>\n",
       "      <td>Thread 1: ðŸŽ¯ Sales Strategies\\n\\nMonika: Hey gu...</td>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>1</td>\n",
       "      <td>5.00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1705.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568514</td>\n",
       "      <td>0.422952</td>\n",
       "      <td>-0.514071</td>\n",
       "      <td>-0.448722</td>\n",
       "      <td>-0.039814</td>\n",
       "      <td>-0.403350</td>\n",
       "      <td>7.867165</td>\n",
       "      <td>2.458412</td>\n",
       "      <td>1.289622</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20415</th>\n",
       "      <td>false_qa</td>\n",
       "      <td>What kind of hyraxes live on Arctic?</td>\n",
       "      <td>Hyraxes, which are also known as rock hyraxes ...</td>\n",
       "      <td>starchat</td>\n",
       "      <td>0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214928</td>\n",
       "      <td>-0.320559</td>\n",
       "      <td>0.794081</td>\n",
       "      <td>0.771938</td>\n",
       "      <td>-0.012302</td>\n",
       "      <td>0.525352</td>\n",
       "      <td>-3.947242</td>\n",
       "      <td>-1.381677</td>\n",
       "      <td>-0.628615</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20414 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              source                                             prompt  \\\n",
       "0      evol_instruct  Which word does not belong in the following gr...   \n",
       "1          ultrachat  In what ways has technology changed the way in...   \n",
       "2       flan_v2_niv2  Detailed Instructions: In this task you are gi...   \n",
       "3          ultrachat      What are the best snorkeling spots in Hawaii?   \n",
       "4           false_qa  Why do anaerobic bacteria prefer an environmen...   \n",
       "...              ...                                                ...   \n",
       "20411   flan_v2_niv2  You will be given a sentence that describes a ...   \n",
       "20412  evol_instruct  How can I modify the existing C# code to also ...   \n",
       "20413   flan_v2_niv2  Find the movie name from the given conversatio...   \n",
       "20414       sharegpt  Create a slack conversation between 4 people, ...   \n",
       "20415       false_qa               What kind of hyraxes live on Arctic?   \n",
       "\n",
       "                                                response                model  \\\n",
       "0      Kettle does not belong in the group as it is a...         wizardlm-70b   \n",
       "1      I do not have personal views or opinions. howe...          ultralm-65b   \n",
       "2      Pangaea and Gondwana were two supercontinents ...     llama-2-70b-chat   \n",
       "3      Hawaii is famous for its breathtaking underwat...                gpt-4   \n",
       "4      Anaerobic bacteria do not prefer an environmen...         mpt-30b-chat   \n",
       "...                                                  ...                  ...   \n",
       "20411  Could you please verify the categories and the...  falcon-40b-instruct   \n",
       "20412  To modify the existing code to calculate the e...         wizardlm-70b   \n",
       "20413                                      The Lion King                gpt-4   \n",
       "20414  Thread 1: ðŸŽ¯ Sales Strategies\\n\\nMonika: Hey gu...         wizardlm-13b   \n",
       "20415  Hyraxes, which are also known as rock hyraxes ...             starchat   \n",
       "\n",
       "       chosen  rating  n_sents  n_words  n_uniquewords  n_chars  ...  \\\n",
       "0           0    4.50      1.0     25.0           24.0     96.0  ...   \n",
       "1           0    4.25     13.0    259.0          141.0   1338.0  ...   \n",
       "2           0    3.25      5.0     97.0           56.0    517.0  ...   \n",
       "3           1    5.00     25.0    403.0          183.0   2034.0  ...   \n",
       "4           1    4.50      4.0     79.0           52.0    386.0  ...   \n",
       "...       ...     ...      ...      ...            ...      ...  ...   \n",
       "20411       0    2.00      2.0     30.0           26.0    162.0  ...   \n",
       "20412       0    4.00     14.0    390.0          150.0   2122.0  ...   \n",
       "20413       1    4.50      1.0      3.0            3.0     11.0  ...   \n",
       "20414       1    5.00     29.0    361.0          201.0   1705.0  ...   \n",
       "20415       0    2.75      3.0     88.0           62.0    399.0  ...   \n",
       "\n",
       "       hdd_z_score  flesch_score_z_score  flesch_grade_z_score  \\\n",
       "0         1.580441              0.793446             -0.155766   \n",
       "1         0.185218             -0.306184              0.331115   \n",
       "2        -0.654118             -0.340191              0.328534   \n",
       "3         0.281771              0.037216             -0.080562   \n",
       "4        -0.793461             -0.399084              0.384574   \n",
       "...            ...                   ...                   ...   \n",
       "20411     0.518269             -0.307540              0.094814   \n",
       "20412    -0.361023             -1.138155              1.266837   \n",
       "20413     2.035658              1.105190             -1.423146   \n",
       "20414     0.568514              0.422952             -0.514071   \n",
       "20415    -0.214928             -0.320559              0.794081   \n",
       "\n",
       "       gunning_fog_z_score  coleman_liau_z_score  \\\n",
       "0                -0.326385             -0.467108   \n",
       "1                 0.290942              0.333853   \n",
       "2                 0.219528              0.432542   \n",
       "3                -0.218502              0.221718   \n",
       "4                 0.457682              0.156561   \n",
       "...                    ...                   ...   \n",
       "20411             0.373319              0.428784   \n",
       "20412             1.272938              0.551847   \n",
       "20413            -1.865734             -1.503475   \n",
       "20414            -0.448722             -0.039814   \n",
       "20415             0.771938             -0.012302   \n",
       "\n",
       "       automated_readability_z_score  linear_metric      PCA1  weighted_pca  \\\n",
       "0                          -0.143045      -8.507311 -2.935682     -1.893228   \n",
       "1                           0.312785       3.848131  1.195098      0.847282   \n",
       "2                           0.375533      -3.735004 -1.244462     -0.547941   \n",
       "3                           0.010123       9.132258  2.909264      1.700674   \n",
       "4                           0.140014      -4.842261 -1.526221     -0.758836   \n",
       "...                              ...            ...       ...           ...   \n",
       "20411                       0.145619      -7.026232 -2.289629     -1.185295   \n",
       "20412                       0.959843      10.339279  3.359946      2.371094   \n",
       "20413                      -1.596003     -14.783595 -4.272149     -3.193378   \n",
       "20414                      -0.403350       7.867165  2.458412      1.289622   \n",
       "20415                       0.525352      -3.947242 -1.381677     -0.628615   \n",
       "\n",
       "       gmean  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  \n",
       "...      ...  \n",
       "20411    NaN  \n",
       "20412    NaN  \n",
       "20413    NaN  \n",
       "20414    NaN  \n",
       "20415    NaN  \n",
       "\n",
       "[20414 rows x 56 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000004"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_subset = df_all[df_all['chosen'] == 1]\n",
    "rejected_subset = df_all[df_all['chosen'] == 0]\n",
    "\n",
    "gmean_chosen_response_metric_pairs = pd.DataFrame({'response': chosen_subset.loc[:, 'response'], 'score': chosen_subset.loc[:, 'Gmean']}).reset_index(drop=True)\n",
    "gmean_rejected_response_metric_pairs = pd.DataFrame({'response': rejected_subset.loc[:, 'response'], 'score': rejected_subset.loc[:, 'Gmean']}).reset_index(drop=True)\n",
    "\n",
    "#Let's check out the stats on the metric real quick:\n",
    "gmean_metric_distribution = pd.DataFrame({'Group': ['Accepted', 'Rejected'], \n",
    "                        'Mean' : [Linear_chosen_response_metric_pairs['score'].mean(), Linear_rejected_response_metric_pairs['score'].mean()], \n",
    "                        'Standard Deviaton': [np.std(Linear_chosen_response_metric_pairs['score']), np.std(Linear_rejected_response_metric_pairs['score'])],\n",
    "                        'Variance': [np.var(Linear_chosen_response_metric_pairs['score']), np.var(Linear_rejected_response_metric_pairs['score'])],\n",
    "                        'Max': [Linear_chosen_response_metric_pairs['score'].max(), Linear_rejected_response_metric_pairs['score'].max()],\n",
    "                        'Min': [Linear_chosen_response_metric_pairs['score'].min(), Linear_rejected_response_metric_pairs['score'].min()]}) \n",
    "\n",
    "gmean_metric_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'PCA Explained Variance')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "\n",
    "pca.fit(df_all[relevant_z_scores])\n",
    "features = range(pca.n_components_)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(features, pca.explained_variance_ratio_ * 100)\n",
    "ax.set_xlabel(\"PCA feature\")\n",
    "ax.set_ylabel(\"Prop explained Variance\")\n",
    "ax.set_title(\"PCA Explained Variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_components = pca.fit_transform(df_all[relevant_z_scores])\n",
    "fpc = pca_components[:, 0]\n",
    "\n",
    "df_all.loc[:, 'PCA1'] = fpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviaton</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accepted</td>\n",
       "      <td>0.494276</td>\n",
       "      <td>3.050283</td>\n",
       "      <td>9.304225</td>\n",
       "      <td>12.414935</td>\n",
       "      <td>-5.52919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>-0.494373</td>\n",
       "      <td>2.638178</td>\n",
       "      <td>6.959982</td>\n",
       "      <td>16.422423</td>\n",
       "      <td>-5.52919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Group      Mean  Standard Deviaton  Variance        Max      Min\n",
       "0  Accepted  0.494276           3.050283  9.304225  12.414935 -5.52919\n",
       "1  Rejected -0.494373           2.638178  6.959982  16.422423 -5.52919"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_subset = df_all[df_all['chosen'] == 1]\n",
    "rejected_subset = df_all[df_all['chosen'] == 0]\n",
    "\n",
    "PCA_chosen_response_metric_pairs = pd.DataFrame({'response': chosen_subset.loc[:, 'response'], 'score': chosen_subset.loc[:, 'PCA1']}).reset_index(drop=True)\n",
    "PCA_rejected_response_metric_pairs = pd.DataFrame({'response': rejected_subset.loc[:, 'response'], 'score': rejected_subset.loc[:, 'PCA1']}).reset_index(drop=True)\n",
    "\n",
    "#Let's check out the stats on the metric real quick:\n",
    "PCA_metric_distribution = pd.DataFrame({'Group': ['Accepted', 'Rejected'], \n",
    "                        'Mean' : [PCA_chosen_response_metric_pairs['score'].mean(), PCA_rejected_response_metric_pairs['score'].mean()], \n",
    "                        'Standard Deviaton': [np.std(PCA_chosen_response_metric_pairs['score']), np.std(PCA_rejected_response_metric_pairs['score'])],\n",
    "                        'Variance': [np.var(PCA_chosen_response_metric_pairs['score']), np.var(PCA_rejected_response_metric_pairs['score'])],\n",
    "                        'Max': [PCA_chosen_response_metric_pairs['score'].max(), PCA_rejected_response_metric_pairs['score'].max()],\n",
    "                        'Min': [PCA_chosen_response_metric_pairs['score'].min(), PCA_rejected_response_metric_pairs['score'].min()]}) \n",
    "\n",
    "PCA_metric_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca['accepted_pca1'] = None\n",
    "df_pca['rejected_pca1'] = None\n",
    "\n",
    "for i in range(len(df_pca)):\n",
    "    df_pca.iloc[i, df_pca.columns.get_loc('accepted_pca1')]= PCA_chosen_response_metric_pairs.iloc[np.where(PCA_chosen_response_metric_pairs['response'] == df_pca['chosen'][i])[0][0], -1]\n",
    "    df_pca.iloc[i, df_pca.columns.get_loc('rejected_pca1')] = PCA_rejected_response_metric_pairs.iloc[np.where(PCA_rejected_response_metric_pairs['response'] == df_pca['rejected'][i])[0][0], -1]\n",
    "\n",
    "df_pca['diff_pca1'] = df_pca['accepted_pca1'] - df_pca['rejected_pca1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca.to_csv(\"pca_metric_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might as well do a weighted Linear sum of all the features and their weights, although it really only takes 5 to get 96%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weighted_pca = df_clean.copy()\n",
    "\n",
    "pca_weighted = PCA()\n",
    "\n",
    "pca_weighted_comps = pca_weighted.fit_transform(df_all[relevant_z_scores])\n",
    "pca_weighted_exp_var_rat = pca_weighted.explained_variance_ratio_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviaton</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accepted</td>\n",
       "      <td>0.30652</td>\n",
       "      <td>1.982479</td>\n",
       "      <td>3.930224</td>\n",
       "      <td>22.151480</td>\n",
       "      <td>-4.846351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>-0.30658</td>\n",
       "      <td>1.762129</td>\n",
       "      <td>3.105097</td>\n",
       "      <td>20.452313</td>\n",
       "      <td>-4.846351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Group     Mean  Standard Deviaton  Variance        Max       Min\n",
       "0  Accepted  0.30652           1.982479  3.930224  22.151480 -4.846351\n",
       "1  Rejected -0.30658           1.762129  3.105097  20.452313 -4.846351"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.loc[:, 'weighted_pca'] = pca_weighted_comps @ pca_weighted_exp_var_rat\n",
    "\n",
    "chosen_subset = df_all[df_all['chosen'] == 1]\n",
    "rejected_subset = df_all[df_all['chosen'] == 0]\n",
    "\n",
    "weighted_PCA_chosen_response_metric_pairs = pd.DataFrame({'response': chosen_subset.loc[:, 'response'], 'score': chosen_subset.loc[:, 'weighted_pca']}).reset_index(drop=True)\n",
    "weighted_PCA_rejected_response_metric_pairs = pd.DataFrame({'response': rejected_subset.loc[:, 'response'], 'score': rejected_subset.loc[:, 'weighted_pca']}).reset_index(drop=True)\n",
    "\n",
    "#Let's check out the stats on the metric real quick:\n",
    "weighted_PCA_metric_distribution = pd.DataFrame({'Group': ['Accepted', 'Rejected'], \n",
    "                        'Mean' : [weighted_PCA_chosen_response_metric_pairs['score'].mean(), weighted_PCA_rejected_response_metric_pairs['score'].mean()], \n",
    "                        'Standard Deviaton': [np.std(weighted_PCA_chosen_response_metric_pairs['score']), np.std(weighted_PCA_rejected_response_metric_pairs['score'])],\n",
    "                        'Variance': [np.var(weighted_PCA_chosen_response_metric_pairs['score']), np.var(weighted_PCA_rejected_response_metric_pairs['score'])],\n",
    "                        'Max': [weighted_PCA_chosen_response_metric_pairs['score'].max(), weighted_PCA_rejected_response_metric_pairs['score'].max()],\n",
    "                        'Min': [weighted_PCA_chosen_response_metric_pairs['score'].min(), weighted_PCA_rejected_response_metric_pairs['score'].min()]}) \n",
    "\n",
    "weighted_PCA_metric_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weighted_pca['accepted_wpca'] = None\n",
    "df_weighted_pca['rejected_wpca'] = None\n",
    "\n",
    "for i in range(len(df_pca)):\n",
    "    df_weighted_pca.iloc[i, df_weighted_pca.columns.get_loc('accepted_wpca')]= weighted_PCA_chosen_response_metric_pairs.iloc[np.where(weighted_PCA_chosen_response_metric_pairs['response'] == df_weighted_pca['chosen'][i])[0][0], -1]\n",
    "    df_weighted_pca.iloc[i, df_weighted_pca.columns.get_loc('rejected_wpca')] = weighted_PCA_rejected_response_metric_pairs.iloc[np.where(weighted_PCA_rejected_response_metric_pairs['response'] == df_weighted_pca['rejected'][i])[0][0], -1]\n",
    "\n",
    "df_weighted_pca['diff_wpca'] = df_weighted_pca['accepted_wpca'] - df_weighted_pca['rejected_wpca']\n",
    "\n",
    "df_weighted_pca = df_weighted_pca.drop(columns=['accepted_linear_metric', 'rejected_linear_metric', 'diff_linear_metric'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weighted_pca.to_csv('weighted_pca.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which topics have the highest entropy/lowest entropy? n_polysylwords, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_uniquewords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Healthy Lifestyle Exploration</th>\n",
       "      <td>161.350560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Environmental Impact Solutions</th>\n",
       "      <td>140.747352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urban Exploration</th>\n",
       "      <td>138.836694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marketing Strategy Platform</th>\n",
       "      <td>138.130298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Creative Writing</th>\n",
       "      <td>111.754293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi-dimensional Gaming</th>\n",
       "      <td>100.490716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Culinary Creations</th>\n",
       "      <td>99.736897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Childhood Stress and Health</th>\n",
       "      <td>91.819386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cultural Expression</th>\n",
       "      <td>91.467339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Interconnected Systems</th>\n",
       "      <td>85.572553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaming Economics</th>\n",
       "      <td>78.957237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender and Clothing Perceptions</th>\n",
       "      <td>57.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Movie Analysis and Interpretation</th>\n",
       "      <td>54.311149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Analyzing Product Sentiment</th>\n",
       "      <td>54.192308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Language Analysis</th>\n",
       "      <td>46.291001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Natural Language Processing</th>\n",
       "      <td>34.863636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   n_uniquewords\n",
       "topic_name                                      \n",
       "Healthy Lifestyle Exploration         161.350560\n",
       "Environmental Impact Solutions        140.747352\n",
       "Urban Exploration                     138.836694\n",
       "Marketing Strategy Platform           138.130298\n",
       "Creative Writing                      111.754293\n",
       "Multi-dimensional Gaming              100.490716\n",
       "Culinary Creations                     99.736897\n",
       "Childhood Stress and Health            91.819386\n",
       "Cultural Expression                    91.467339\n",
       "Interconnected Systems                 85.572553\n",
       "Gaming Economics                       78.957237\n",
       "Gender and Clothing Perceptions        57.604895\n",
       "Movie Analysis and Interpretation      54.311149\n",
       "Analyzing Product Sentiment            54.192308\n",
       "Language Analysis                      46.291001\n",
       "Natural Language Processing            34.863636"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df_all.groupby('topic_name')['n_uniquewords'].agg('mean')).sort_values(by='n_uniquewords', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which documents have the highest entropy/lowest entropy? n_polysylwords, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_name</th>\n",
       "      <th>n_uniquewords</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>Creative Writing</td>\n",
       "      <td>424.0</td>\n",
       "      <td>Title: Crescendo of the Heart\\n\\nChapter One -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8349</th>\n",
       "      <td>Environmental Impact Solutions</td>\n",
       "      <td>404.0</td>\n",
       "      <td>Title: The Impact of Artificial Intelligence o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20090</th>\n",
       "      <td>Healthy Lifestyle Exploration</td>\n",
       "      <td>392.0</td>\n",
       "      <td>Title: Electronic Voting Systems: A Glimpse in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>Culinary Creations</td>\n",
       "      <td>377.0</td>\n",
       "      <td>What purpose does frosting serve, and how does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3702</th>\n",
       "      <td>Cultural Expression</td>\n",
       "      <td>373.0</td>\n",
       "      <td>**In the acrid vapors of a renewed and retched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17937</th>\n",
       "      <td>Urban Exploration</td>\n",
       "      <td>368.0</td>\n",
       "      <td>Hello! I'm here to help you format your Markdo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>Marketing Strategy Platform</td>\n",
       "      <td>361.0</td>\n",
       "      <td>Title: On-the-Spot Business Plan\\n\\nExecutive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>Multi-dimensional Gaming</td>\n",
       "      <td>360.0</td>\n",
       "      <td>Of course! I'm glad to help you with that. Her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18392</th>\n",
       "      <td>Gaming Economics</td>\n",
       "      <td>345.0</td>\n",
       "      <td>Title: \"Fortnite Battle Royale Beginner's Guid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>Analyzing Product Sentiment</td>\n",
       "      <td>314.0</td>\n",
       "      <td>Title: The North Water\\nTrailer Link: https://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18637</th>\n",
       "      <td>Gender and Clothing Perceptions</td>\n",
       "      <td>312.0</td>\n",
       "      <td>50% Tocopheryl Acetate, Simpleslide-out Switch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Interconnected Systems</td>\n",
       "      <td>307.0</td>\n",
       "      <td>Ah, a day on Mars! *excited tone* Living on Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>Childhood Stress and Health</td>\n",
       "      <td>306.0</td>\n",
       "      <td>Title: The Tapestry of Relationships\\n\\nOnce u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15217</th>\n",
       "      <td>Movie Analysis and Interpretation</td>\n",
       "      <td>301.0</td>\n",
       "      <td>In the midst of World War II, danger and intri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17648</th>\n",
       "      <td>Language Analysis</td>\n",
       "      <td>270.0</td>\n",
       "      <td>Here are 50 words that match that description:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15661</th>\n",
       "      <td>Natural Language Processing</td>\n",
       "      <td>159.0</td>\n",
       "      <td>It's important for an AI assistant to ensure t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              topic_name  n_uniquewords  \\\n",
       "1730                    Creative Writing          424.0   \n",
       "8349      Environmental Impact Solutions          404.0   \n",
       "20090      Healthy Lifestyle Exploration          392.0   \n",
       "2936                  Culinary Creations          377.0   \n",
       "3702                 Cultural Expression          373.0   \n",
       "17937                  Urban Exploration          368.0   \n",
       "2075         Marketing Strategy Platform          361.0   \n",
       "2946            Multi-dimensional Gaming          360.0   \n",
       "18392                   Gaming Economics          345.0   \n",
       "4580         Analyzing Product Sentiment          314.0   \n",
       "18637    Gender and Clothing Perceptions          312.0   \n",
       "367               Interconnected Systems          307.0   \n",
       "1993         Childhood Stress and Health          306.0   \n",
       "15217  Movie Analysis and Interpretation          301.0   \n",
       "17648                  Language Analysis          270.0   \n",
       "15661        Natural Language Processing          159.0   \n",
       "\n",
       "                                                response  \n",
       "1730   Title: Crescendo of the Heart\\n\\nChapter One -...  \n",
       "8349   Title: The Impact of Artificial Intelligence o...  \n",
       "20090  Title: Electronic Voting Systems: A Glimpse in...  \n",
       "2936   What purpose does frosting serve, and how does...  \n",
       "3702   **In the acrid vapors of a renewed and retched...  \n",
       "17937  Hello! I'm here to help you format your Markdo...  \n",
       "2075   Title: On-the-Spot Business Plan\\n\\nExecutive ...  \n",
       "2946   Of course! I'm glad to help you with that. Her...  \n",
       "18392  Title: \"Fortnite Battle Royale Beginner's Guid...  \n",
       "4580   Title: The North Water\\nTrailer Link: https://...  \n",
       "18637  50% Tocopheryl Acetate, Simpleslide-out Switch...  \n",
       "367    Ah, a day on Mars! *excited tone* Living on Ma...  \n",
       "1993   Title: The Tapestry of Relationships\\n\\nOnce u...  \n",
       "15217  In the midst of World War II, danger and intri...  \n",
       "17648  Here are 50 words that match that description:...  \n",
       "15661  It's important for an AI assistant to ensure t...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_example = df_all.sort_values(by=['n_uniquewords', 'topic_name'], ascending=[False, False])\n",
    "df_example = df_example.groupby('topic_name').head(1)\n",
    "df_example = df_example[['topic_name', 'n_uniquewords', 'response']]\n",
    "df_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
